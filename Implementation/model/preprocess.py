import os

import pandas
import numpy as np
from blstmmodel import BLSTM
from sklearn.metrics import confusion_matrix


def model(filename, vector_length):
    base = os.path.splitext(os.path.basename(filename))[0]
    vector_filename = base + "_gadget_vectors.pkl"
    path = os.path.join("../data", vector_filename)
    if os.path.exists(path):
        df = pandas.read_pickle(path)
        blstm = BLSTM(df, name=base)
        blstm.train()
        return blstm.test()


def decision(pre, test):
    count, yes = 0, 0
    for i in range(0, len(pre)):
        if pre[i] >= 2:
            pre[i] = 1
        else:
            pre[i] = 0
        test[i] = test[i] / 3
        count += 1
        if test[i] == pre[i]:
            yes += 1
    ac = yes / count
    print("Accuracy is...", ac)
    tn, fp, fn, tp = confusion_matrix(test, pre).ravel()
    print('False positive rate is...', fp / (fp + tn))
    print('False negative rate is...', fn / (fn + tp))
    recall = tp / (tp + fn)
    print('True positive rate is...', recall)
    precision = tp / (tp + fp)
    print('Precision is...', precision)
    print('F1 score is...', (2 * precision * recall) / (precision + recall))
    return


def main():
    vector_length = 100
    source_test, source_pre = model("code.txt", vector_length)
    compile_test, compile_pre = model("compile_code.txt", vector_length)
    compile_test, fusion_pre = model("fusion#code#compile_code.txt", vector_length)
    pre = np.argmax(source_pre, axis=1) + np.argmax(compile_pre, axis=1) + np.argmax(fusion_pre, axis=1)
    test = np.argmax(source_test, axis=1) + np.argmax(compile_test, axis=1) + np.argmax(compile_test, axis=1)
    decision(pre, test)


if __name__ == "__main__":
    main()
